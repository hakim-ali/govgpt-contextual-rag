version: '3.8'

services:
  # RAG Server for local development and testing
  rag-server:
    build: .
    container_name: govgpt-rag-server-local
    ports:
      - "8100:8100"
    volumes:
      # Mount artifacts directory from Pipeline folder
      - ./artifacts:/app/artifacts:ro
    env_file:
      - .env
    environment:
      # Override specific Docker environment settings
      - ARTIFACT_DIR=/app/artifacts
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      # Default model configurations (can be overridden in .env)
      - RAG_MODEL=${RAG_MODEL:-gpt-4.1}
      - EMBED_MODEL=${EMBED_MODEL:-text-embedding-3-large}
      - VECTOR_K=${VECTOR_K:-75}
      - BM25_K=${BM25_K:-75}
      - TOP_K=${TOP_K:-20}
      - TOP_N=${TOP_N:-5}
      - RRF_K=${RRF_K:-60}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rag-network

  # Optional: Pipeline testing service (for integration testing)
  pipeline-test:
    build: .
    container_name: govgpt-pipeline-test
    depends_on:
      - rag-server
    environment:
      - PYTHONPATH=/app
      - RAG_SERVER_URL=http://rag-server:8100
      - ENABLE_DEBUG=true
    volumes:
      - ./:/app/pipeline
    working_dir: /app/pipeline
    command: ["python", "test_pipeline.py"]
    networks:
      - rag-network
    profiles:
      - testing

networks:
  rag-network:
    driver: bridge

# Optional: Add volumes for persistence if needed
volumes:
  artifacts:
    driver: local